<?xml version="1.0" encoding="UTF-8"?>
<project xmlns="http://maven.apache.org/POM/4.0.0"
         xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance"
         xsi:schemaLocation="http://maven.apache.org/POM/4.0.0 http://maven.apache.org/xsd/maven-4.0.0.xsd">
  <modelVersion>4.0.0</modelVersion>

  <groupId>co.cask.hydrator</groupId>
  <artifactId>azure-event-hub</artifactId>
  <version>1.0.0-${scala.binary.version}</version>
  <licenses>
    <license>
      <name>The Apache Software License, Version 2.0</name>
      <url>http://www.apache.org/licenses/LICENSE-2.0.txt</url>
      <distribution>repo</distribution>
      <comments>A business-friendly OSS license</comments>
    </license>
  </licenses>

  <developers>
    <developer>
      <name>Cask Data</name>
      <email>cask-dev@googlegroups.com</email>
      <organization>Cask Data, Inc.</organization>
      <organizationUrl>http://www.cdap.io</organizationUrl>
    </developer>
  </developers>

  <issueManagement>
    <url>https://issues.cask.co/browse/HYDRATOR</url>
  </issueManagement>

  <distributionManagement>
    <repository>
      <id>sonatype.release</id>
      <url>https://oss.sonatype.org/service/local/staging/deploy/maven2</url>
    </repository>
    <snapshotRepository>
      <id>sonatype.snapshots</id>
      <url>https://oss.sonatype.org/content/repositories/snapshots</url>
    </snapshotRepository>
    <site>
      <id>cask</id>
      <url>http://cask.co</url>
    </site>
  </distributionManagement>

  <repositories>
    <repository>
      <id>sonatype.release</id>
      <url>https://oss.sonatype.org/service/local/staging/deploy/maven2</url>
    </repository>
    <repository>
      <id>sonatype-snapshots</id>
      <url>https://oss.sonatype.org/content/repositories/snapshots</url>
    </repository>
  </repositories>

  <properties>
    <project.build.sourceEncoding>UTF-8</project.build.sourceEncoding>
    <cdap.version>4.2.0</cdap.version>
    <hydrator.version>1.7.0</hydrator.version>
    <widgets.dir>widgets</widgets.dir>
    <docs.dir>docs</docs.dir>
    <!-- properties for script build step that creates the config files for the artifacts -->
    <app.parents>system:cdap-data-streams[4.2.0,4.3.0-SNAPSHOT)</app.parents>
    <main.basedir>${project.basedir}</main.basedir>
    <scala.binary.version>2.10</scala.binary.version>
    <spark.version>1.6.1</spark.version>
    <event.hub.version>1.6.3</event.hub.version>
  </properties>

  <dependencies>
    <dependency>
      <groupId>co.cask.cdap</groupId>
      <artifactId>cdap-etl-api</artifactId>
      <version>${cdap.version}</version>
      <scope>provided</scope>
    </dependency>
    <dependency>
      <groupId>co.cask.cdap</groupId>
      <artifactId>hydrator-test</artifactId>
      <version>${cdap.version}</version>
      <scope>provided</scope>
      <exclusions>
        <exclusion>
          <groupId>io.netty</groupId>
          <artifactId>netty</artifactId>
        </exclusion>
      </exclusions>
    </dependency>
    <dependency>
      <groupId>co.cask.cdap</groupId>
      <artifactId>cdap-data-pipeline</artifactId>
      <version>${cdap.version}</version>
      <scope>provided</scope>
    </dependency>
    <dependency>
      <groupId>co.cask.cdap</groupId>
      <artifactId>cdap-formats</artifactId>
      <version>${cdap.version}</version>
    </dependency>
    <dependency>
      <groupId>co.cask.hydrator</groupId>
      <artifactId>hydrator-common</artifactId>
      <version>${hydrator.version}</version>
    </dependency>
    <dependency>
      <groupId>com.microsoft.azure</groupId>
      <artifactId>spark-streaming-eventhubs_${scala.binary.version}</artifactId>
      <version>${event.hub.version}</version>
    </dependency>
    <dependency>
      <groupId>org.apache.spark</groupId>
      <artifactId>spark-core_${scala.binary.version}</artifactId>
      <version>${spark.version}</version>
      <scope>provided</scope>
      <exclusions>
        <exclusion>
          <groupId>org.slf4j</groupId>
          <artifactId>slf4j-log4j12</artifactId>
        </exclusion>
        <exclusion>
          <groupId>io.netty</groupId>
          <artifactId>netty</artifactId>
        </exclusion>
        <exclusion>
          <groupId>log4j</groupId>
          <artifactId>log4j</artifactId>
        </exclusion>
        <exclusion>
          <groupId>org.apache.hadoop</groupId>
          <artifactId>hadoop-client</artifactId>
        </exclusion>
        <exclusion>
          <groupId>com.esotericsoftware.reflectasm</groupId>
          <artifactId>reflectasm</artifactId>
        </exclusion>
        <exclusion>
          <groupId>org.apache.curator</groupId>
          <artifactId>curator-recipes</artifactId>
        </exclusion>
        <exclusion>
          <groupId>org.tachyonproject</groupId>
          <artifactId>tachyon-client</artifactId>
        </exclusion>
        <exclusion>
          <groupId>org.scala-lang</groupId>
          <artifactId>scala-compiler</artifactId>
        </exclusion>
        <exclusion>
          <groupId>org.eclipse.jetty.orbit</groupId>
          <artifactId>javax.servlet</artifactId>
        </exclusion>
        <exclusion>
          <groupId>net.java.dev.jets3t</groupId>
          <artifactId>jets3t</artifactId>
        </exclusion>
      </exclusions>
    </dependency>
  </dependencies>

  <build>
    <pluginManagement>
      <plugins>
        <plugin>
          <groupId>org.apache.maven.plugins</groupId>
          <artifactId>maven-compiler-plugin</artifactId>
          <version>3.1</version>
          <configuration>
            <source>1.7</source>
            <target>1.7</target>
          </configuration>
        </plugin>
        <plugin>
          <groupId>org.apache.felix</groupId>
          <artifactId>maven-bundle-plugin</artifactId>
          <version>2.5.4</version>
          <extensions>true</extensions>
          <configuration>
            <instructions>
              <_exportcontents>co.cask.hydrator.plugin.*;org.apache.spark.streaming.eventhubs.*;
                com.microsoft.azure.eventhubs.*</_exportcontents>
              <Embed-Dependency>*;inline=false;scope=compile</Embed-Dependency>
              <Embed-Transitive>true</Embed-Transitive>
              <Embed-Directory>lib</Embed-Directory>
            </instructions>
          </configuration>
          <executions>
            <execution>
              <phase>package</phase>
              <goals>
                <goal>bundle</goal>
              </goals>
            </execution>
          </executions>
        </plugin>
        <plugin>
          <groupId>org.apache.maven.plugins</groupId>
          <artifactId>maven-antrun-plugin</artifactId>
          <version>1.7</version>
          <executions>
            <execution>
              <id>create-artifact-config</id>
              <phase>prepare-package</phase>
              <configuration>
                <target>
                  <script language="javascript"> <![CDATA[

                  // for some reason, project.basedir evaluates to null if we just get the property here.
                  // so we set main.basedir to project.basedir in the pom properties, then main.basedir is used here
                  // where it evaluates correctly for whatever reason
                  var baseDir = project.getProperty("main.basedir");
                  var targetDir = project.getProperty("project.build.directory");
                  var artifactId = project.getProperty("project.artifactId");
                  var version = project.getProperty("project.version");

                  var cfgFile = new java.io.File(targetDir, artifactId + "-" + version + ".json");

                  if (!cfgFile.exists()) {
                    cfgFile.createNewFile();
                  }

                  var parents = project.getProperty("app.parents").split(",");
                  var config = {
                    "parents": [ ],
                    "properties": {}
                  }
                  for (i = 0; i < parents.length; i+=2) {
                    // because name1[lo,hi],name2[lo,hi] gets split into "name1[lo", "hi]", "name2[lo", "hi]"
                    // so we have to combine them again
                    config.parents.push(parents[i] + "," + parents[i+1]);
                  }

                  // look in widgets directory for widget config for each plugin
                  var widgetsDir = new java.io.File(baseDir, project.getProperty("widgets.dir"));
                  if (widgetsDir.isDirectory()) {
                    var widgetsFiles = widgetsDir.listFiles();
                    for (i = 0; i < widgetsFiles.length; i++) {
                      var widgetsFile = widgetsFiles[i];
                      if (widgetsFile.isFile()) {
                        var propertyName = "widgets." + widgetsFile.getName();
                        // if the filename ends with .json
                        if (propertyName.indexOf(".json", propertyName.length - 5) !== -1) {
                          // strip the .json
                          propertyName = propertyName.slice(0, -5);
                          var contents = new java.lang.String(java.nio.file.Files.readAllBytes(widgetsFile.toPath()), java.nio.charset.StandardCharsets.UTF_8);
                          var contentsAsJson = JSON.parse(contents);
                          config.properties[propertyName] = JSON.stringify(contentsAsJson);
                        }
                      }
                    }
                  }

                  // look in the docs directory for docs for each plugin
                  var docsDir = new java.io.File(baseDir, project.getProperty("docs.dir"));
                  if (docsDir.isDirectory()) {
                    var docFiles = docsDir.listFiles();
                    for (i = 0; i < docFiles.length; i++) {
                      var docFile = docFiles[i];
                      if (docFile.isFile()) {
                        var propertyName = "doc." + docFile.getName();
                        // if the filename ends with .md
                        if (propertyName.indexOf(".md", propertyName.length - 3) !== -1) {
                          // strip the extension
                          propertyName = propertyName.slice(0, -3);
                          var contents = new java.lang.String(java.nio.file.Files.readAllBytes(docFile.toPath()), java.nio.charset.StandardCharsets.UTF_8);
                          config.properties[propertyName] = contents + "";
                        }
                      }
                    }
                  }

                  var fw = new java.io.BufferedWriter(new java.io.FileWriter(cfgFile.getAbsoluteFile()));
                  fw.write(JSON.stringify(config, null, 2));
                  fw.close();
                ]]></script>
                </target>
              </configuration>
              <goals>
                <goal>run</goal>
              </goals>
            </execution>
          </executions>
        </plugin>
        <plugin>
          <groupId>net.alchim31.maven</groupId>
          <artifactId>scala-maven-plugin</artifactId>
          <version>3.2.2</version>
          <configuration>
            <args>
              <arg>-target:jvm-1.7</arg>
            </args>
          </configuration>
          <executions>
            <execution>
              <id>scala-add-source</id>
              <goals>
                <goal>add-source</goal>
              </goals>
            </execution>
            <execution>
              <id>scala-compile</id>
              <!-- Needs to be before the compile phase -->
              <phase>process-resources</phase>
              <goals>
                <goal>compile</goal>
              </goals>
            </execution>
            <execution>
              <id>scala-test-compile</id>
              <!-- Needs to be before the test-compile phase -->
              <phase>process-test-resources</phase>
              <goals>
                <goal>testCompile</goal>
              </goals>
            </execution>
          </executions>
        </plugin>
      </plugins>
    </pluginManagement>
    <plugins>
      <plugin>
        <groupId>org.apache.maven.plugins</groupId>
        <artifactId>maven-surefire-plugin</artifactId>
        <version>2.14.1</version>
      </plugin>
      <plugin>
        <groupId>org.apache.felix</groupId>
        <artifactId>maven-bundle-plugin</artifactId>
      </plugin>
      <plugin>
        <groupId>org.apache.maven.plugins</groupId>
        <artifactId>maven-antrun-plugin</artifactId>
      </plugin>
      <plugin>
        <groupId>net.alchim31.maven</groupId>
        <artifactId>scala-maven-plugin</artifactId>
      </plugin>
    </plugins>
  </build>
  <!-- Profile for release. Includes signing of jars. -->
  <profiles>
    <profile>
      <properties>
        <scala.binary.version>2.11</scala.binary.version>
        <spark.version>2.1.0</spark.version>
        <event.hub.version>2.0.5</event.hub.version>
      </properties>
      <id>scala-211</id>
      <build>
        <plugins>
          <plugin>
            <groupId>org.codehaus.mojo</groupId>
            <artifactId>build-helper-maven-plugin</artifactId>
            <version>1.8</version>
            <executions>
              <execution>
                <id>add-source</id>
                <phase>generate-sources</phase>
                <goals>
                  <goal>add-source</goal>
                </goals>
                <configuration>
                  <sources>
                    <source>src/main/spark2</source>
                  </sources>
                </configuration>
              </execution>
            </executions>
          </plugin>
        </plugins>
      </build>
    </profile>
    <profile>
      <properties>
        <scala.binary.version>2.10</scala.binary.version>
        <spark.version>1.6.1</spark.version>
        <event.hub.version>1.6.3</event.hub.version>
      </properties>
      <id>scala-210</id>
      <build>
        <plugins>
          <plugin>
            <groupId>org.codehaus.mojo</groupId>
            <artifactId>build-helper-maven-plugin</artifactId>
            <version>1.8</version>
            <executions>
              <execution>
                <id>add-source</id>
                <phase>generate-sources</phase>
                <goals>
                  <goal>add-source</goal>
                </goals>
                <configuration>
                  <sources>
                    <source>src/main/spark1</source>
                  </sources>
                </configuration>
              </execution>
            </executions>
          </plugin>
        </plugins>
      </build>
    </profile>
  </profiles>
</project>